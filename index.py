from openai import OpenAI
from streamlit_option_menu import option_menu
import streamlit as st
import json
import base64
import tempfile
import os

# ======== åˆå§‹åŒ–èˆ‡ä»‹é¢ ========
st.set_page_config(page_title="æœƒè­°å°èƒ½æ‰‹", layout="centered")

# éš±è— Streamlit logo èˆ‡é¸å–®
st.markdown("""
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# Sidebar é¸å–®
with st.sidebar:
    selected = option_menu(
        menu_title="åŠŸèƒ½é¸å–®",
        menu_icon="mic",
        options=["Record", "Upload", "Transcribe", "Summary", "Q&A"],
        icons=["mic", "upload", "file-earmark-text", "chat-left-text", "question-circle"],
        default_index=0,
    )

# è®€å– prompt
with open('prompt.json', 'r', encoding='utf-8') as f:
    prompt_template = json.load(f)

# API Key è¨­å®šï¼ˆå¾ Streamlit secretsï¼‰
API_Key = st.secrets["openai_key"]
client = OpenAI(api_key=API_Key)

# Session åˆå§‹åŒ–
if "transcription" not in st.session_state:
    st.session_state.transcription = None
if "summary" not in st.session_state:
    st.session_state.summary = None
if "audio_path" not in st.session_state:
    st.session_state.audio_path = None

# --- éŒ„éŸ³é é¢ ---
if selected == "Record":
    st.title("ğŸ¤ å³æ™‚éŒ„éŸ³ç³»çµ±")
    audio_file = st.audio_input("é–‹å§‹éŒ„éŸ³", key="recorder")
    if audio_file:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(audio_file.read())
            st.session_state.audio_path = tmp.name
        st.audio(audio_file)
        st.success("éŒ„éŸ³å·²ä¿å­˜ï¼Œè«‹å‰å¾€ã€Œè½‰éŒ„ã€é é€²è¡Œè½‰éŒ„ã€‚")

# --- ä¸Šå‚³é é¢ ---
elif selected == "Upload":
    st.title("ğŸ“¤ ä¸Šå‚³éŸ³è¨Šæª”")
    uploaded_file = st.file_uploader("è«‹ä¸Šå‚³éŸ³è¨Šæª” (wav, mp3, mp4)", type=["wav", "mp3", "mp4"])
    if uploaded_file:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(uploaded_file.read())
            st.session_state.audio_path = tmp.name
        st.audio(uploaded_file)
        st.success("æª”æ¡ˆå·²ä¿å­˜ï¼Œè«‹å‰å¾€ã€Œè½‰éŒ„ã€é é€²è¡Œè½‰éŒ„ã€‚")

# --- è½‰éŒ„é é¢ ---
elif selected == "Transcribe":
    st.title("ğŸ“ èªéŸ³è½‰éŒ„")
    if st.session_state.audio_path is None:
        st.info("è«‹å…ˆéŒ„éŸ³æˆ–ä¸Šå‚³éŸ³è¨Šæª”ã€‚")
    else:
        if st.button("é–‹å§‹è½‰éŒ„"):
            with open(st.session_state.audio_path, "rb") as f:
                transcript = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f,
                    response_format="text"
                )
            st.session_state.transcription = transcript
            st.success("èªéŸ³è¾¨è­˜å®Œæˆï¼")
        if st.session_state.transcription:
            st.text_area("ğŸ“„ è½‰éŒ„çµæœ", st.session_state.transcription, height=300)

# ======== æ‘˜è¦é é¢ ========
if selected == "Summary":
    st.title(" ğŸ”æ‘˜è¦ç”¢ç”Ÿ")
    if not st.session_state.transcription:
        st.warning("è«‹å…ˆå®ŒæˆèªéŸ³è¾¨è­˜ï¼")
    else:
        if st.button("âœï¸ é–‹å§‹æ‘˜è¦"):
            with st.spinner("æ‘˜è¦ä¸­..."):
                prompt_template[1]["content"] = st.session_state.transcription
                summary_response = client.chat.completions.create(
                    model="gpt-4",
                    messages=prompt_template,
                    temperature=0.5
                )
                st.session_state.summary = summary_response.choices[0].message.content
                st.success("æ‘˜è¦å®Œæˆï¼")

        if st.session_state.summary:
            st.markdown("### ğŸ“‹ æ‘˜è¦å…§å®¹")
            st.write(st.session_state.summary)

# ======== å•ç­”é é¢ ========
if selected == "Q&A":
    st.title("ğŸ¤– å•ç­”ç³»çµ±")

    if not st.session_state.transcription:
        st.warning("è«‹å…ˆå®ŒæˆèªéŸ³è¾¨è­˜ï¼")
    else:
        preset_messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½åŠ©æ•™ï¼Œå¹«åŠ©ç”¨æˆ¶åˆ†æèªéŸ³å…§å®¹ã€‚"},
            {"role": "user", "content": st.session_state.transcription},
            {"role": "assistant", "content": "æˆ‘å·²è®€å–èªéŸ³å…§å®¹ï¼Œæœ‰ä»€éº¼æƒ³å•çš„å—ï¼Ÿ"}
        ]

        if "messages" not in st.session_state:
            st.session_state.messages = preset_messages

        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        if prompt := st.chat_input("è«‹è¼¸å…¥ä½ çš„å•é¡Œ"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                for response in client.chat.completions.create(
                    model="gpt-4",
                    messages=st.session_state.messages,
                    stream=True
                ):
                    full_response += response.choices[0].delta.get("content", "")
                    message_placeholder.markdown(full_response + "â–Œ")

                message_placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
