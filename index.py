from openai import OpenAI
from streamlit_option_menu import option_menu
import streamlit as st
import json
import base64
import tempfile
import os

# ======== åˆå§‹åŒ–èˆ‡ä»‹é¢ ========
st.set_page_config(page_title="èªéŸ³è½‰éŒ„ç³»çµ±", layout="centered")

# éš±è— Streamlit logo èˆ‡é¸å–®
st.markdown("""
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# Sidebar é¸å–®
with st.sidebar:
    selected = option_menu(
        menu_title="åŠŸèƒ½é¸å–®",
        menu_icon="mic",
        options=["Record", "Upload", "Transcribe", "Summary", "Q&A"],
        icons=["mic", "upload", "file-earmark-text", "chat-left-text", "question-circle"],
        default_index=0,
    )

# è®€å– prompt
with open('prompt.json', 'r', encoding='utf-8') as f:
    prompt_template = json.load(f)

# API Key è¨­å®šï¼ˆå¾ Streamlit secretsï¼‰
API_Key = st.secrets["openai_key"]
client = OpenAI(api_key=API_Key)

# Session åˆå§‹åŒ–
if "transcription" not in st.session_state:
    st.session_state.transcription = None
if "summary" not in st.session_state:
    st.session_state.summary = None
if "audio_path" not in st.session_state:
    st.session_state.audio_path = None

# ======== éŒ„éŸ³é é¢ ========
if selected == "Record":
    st.title("ğŸ¤ å³æ™‚éŒ„éŸ³ç³»çµ±")
    st.markdown("ä½¿ç”¨ä¸‹æ–¹éŒ„éŸ³æŒ‰éˆ•é–‹å§‹éŒ„éŸ³ï¼Œå®Œæˆå¾Œå¯ä¸‹è¼‰éŸ³è¨Šæª”ã€‚")

    audio_file = st.audio_input("è«‹é»æ“Šé–‹å§‹éŒ„éŸ³", key="audio_recorder")

    if audio_file:
        audio_bytes = audio_file.read()
        st.audio(audio_bytes, format="audio/wav")

        # ä¸‹è¼‰é€£çµ
        b64 = base64.b64encode(audio_bytes).decode()
        href = f'<a href="data:audio/wav;base64,{b64}" download="recording.wav">ğŸ“¥ ä¸‹è¼‰éŒ„éŸ³æª”</a>'
        st.markdown(href, unsafe_allow_html=True)

# ======== ä¸Šå‚³é é¢ ========
if selected == "Upload":
    st.title("ğŸ“¤ ä¸Šå‚³éŸ³è¨Šæª”")

    uploaded_file = st.file_uploader("è«‹ä¸Šå‚³éŸ³è¨Šæª”", type=["mp3", "mp4", "wav"])
    if uploaded_file:
        st.audio(uploaded_file)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(uploaded_file.read())
            st.session_state.audio_path = tmp.name

        st.success("ä¸Šå‚³æˆåŠŸï¼è«‹åˆ‡æ›è‡³ Transcribe é€²è¡ŒèªéŸ³è¾¨è­˜ã€‚")

# ======== èªéŸ³è½‰æ–‡å­— ========
if selected == "Transcribe":
    st.title("ğŸ“ èªéŸ³è½‰æ–‡å­—")
    if not st.session_state.audio_path:
        st.warning("è«‹å…ˆè‡³ Upload é é¢ä¸Šå‚³éŸ³è¨Šæª”ï¼")
    else:
        if st.button("ğŸ™ï¸ é–‹å§‹è¾¨è­˜"):
            with st.spinner("è¾¨è­˜ä¸­..."):
                with open(st.session_state.audio_path, "rb") as f:
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=f,
                        response_format="text"
                    )
                st.session_state.transcription = transcript
                st.success("èªéŸ³è¾¨è­˜å®Œæˆï¼")
        if st.session_state.transcription:
            st.text_area("ğŸ” è¾¨è­˜çµæœ", st.session_state.transcription, height=300)

# ======== æ‘˜è¦é é¢ ========
if selected == "Summary":
    st.title("ğŸ“„ æ‘˜è¦ç”¢ç”Ÿ")
    if not st.session_state.transcription:
        st.warning("è«‹å…ˆå®ŒæˆèªéŸ³è¾¨è­˜ï¼")
    else:
        if st.button("âœï¸ é–‹å§‹æ‘˜è¦"):
            with st.spinner("æ‘˜è¦ä¸­..."):
                prompt_template[1]["content"] = st.session_state.transcription
                summary_response = client.chat.completions.create(
                    model="gpt-4",
                    messages=prompt_template,
                    temperature=0.5
                )
                st.session_state.summary = summary_response.choices[0].message.content
                st.success("æ‘˜è¦å®Œæˆï¼")

        if st.session_state.summary:
            st.markdown("### ğŸ“‹ æ‘˜è¦å…§å®¹")
            st.write(st.session_state.summary)

# ======== å•ç­”é é¢ ========
if selected == "Q&A":
    st.title("ğŸ¤– å•ç­”ç³»çµ±")

    if not st.session_state.transcription:
        st.warning("è«‹å…ˆå®ŒæˆèªéŸ³è¾¨è­˜ï¼")
    else:
        preset_messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½åŠ©æ•™ï¼Œå¹«åŠ©ç”¨æˆ¶åˆ†æèªéŸ³å…§å®¹ã€‚"},
            {"role": "user", "content": st.session_state.transcription},
            {"role": "assistant", "content": "æˆ‘å·²è®€å–èªéŸ³å…§å®¹ï¼Œæœ‰ä»€éº¼æƒ³å•çš„å—ï¼Ÿ"}
        ]

        if "messages" not in st.session_state:
            st.session_state.messages = preset_messages

        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        if prompt := st.chat_input("è«‹è¼¸å…¥ä½ çš„å•é¡Œ"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                for response in client.chat.completions.create(
                    model="gpt-4",
                    messages=st.session_state.messages,
                    stream=True
                ):
                    full_response += response.choices[0].delta.get("content", "")
                    message_placeholder.markdown(full_response + "â–Œ")

                message_placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
